{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "687teS5DZYlF"
      },
      "source": [
        "\n",
        "\n",
        "# Chapter 7 Quiz Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqjNayHVZmgx"
      },
      "source": [
        "Read Chapter 7 of *Essential Math for Data Science* by Thomas Nield. This is available to you through UMGC's Library. When you are ready, work through this notebook to answer these quiz questions. Once you are satisfied with your answers, go to the classroom to submit your answers. You have two attempts, so if you miss a question, come back here to work out another answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJoVQeq9s6vA"
      },
      "source": [
        "This quiz contains 3 additional concept style questions and 1 question involving Python coding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mPwonDiZtGn"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyAZax2cZvS4"
      },
      "source": [
        "Match each terminology with the appropriate explanation for forward propagation method in neural network. Pair up the right answers for all pairs:\n",
        "\n",
        "1. Activation Function `F`\n",
        "2. Input Layer `C`\n",
        "3. Hidden Layers `D`\n",
        "4. Weights and Biases `B`\n",
        "5. Weighted Sum `E`\n",
        "6. Output Layer `A`\n",
        "7. Final Output `G`\n",
        "\n",
        "A. The output layer produces the final prediction or output of the neural network based on the input data.\n",
        "\n",
        "B. Each connection between neurons in the neural network has an associated weight and bias.\n",
        "\n",
        "C. The input layer consists of the input features or variables, representing information about the input data.\n",
        "\n",
        "D. If the neural network has hidden layers, the input data is passed through these layers before reaching the output layer.\n",
        "\n",
        "E. In each neuron, the inputs from the previous layer are multiplied by the corresponding weights and summed up along with the bias term.\n",
        "\n",
        "F. After the weighted sum is calculated, an activation function is applied to introduce non-linearity into the network.\n",
        "\n",
        "G. The output could represent the probability of belonging to a certain class in a binary classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO9l4SpAdf5X"
      },
      "source": [
        "# Question 2\n",
        "True of False:\n",
        "\n",
        "In the context of neural networks, forward propagation refers to the process of passing input data through the network and calculating the output values of each layer.\n",
        "\n",
        "`True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QRyfJjReqTR"
      },
      "source": [
        "# Question 3\n",
        "True or False\n",
        "\n",
        "Backward propagation, also known as backpropagation, is the process of calculating the gradients of the network's parameters in a neural network.\n",
        "It involves calculating the gradients of the loss function with respect to the network's parameters and updating the parameters using gradient descent.\n",
        "\n",
        "`True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLECBwKNZwWj"
      },
      "source": [
        "# Questions 4-6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N_2zcYvZ1Oc"
      },
      "source": [
        "Generate a synthetic dataset for binary classification with the following parameters marked with a question mark (?) in the code below.\n",
        "\n",
        "*1000 samples, 10 features, 5 informative features, 0 redundent features, random_state is 42.*\n",
        "\n",
        "Split the dataset into training and testing sets (80/20).Remember, you only have to enter for either training or testing. Look for a question mark (?).\n",
        "\n",
        "Enter an activation function of \"tanh\" which is a hyperbolic tan function. Look for a question mark (?).\n",
        "\n",
        "Run the Python program to compare the accuracies of different activation functions:\n",
        "\n",
        "1. Tangent Hyperbolic,\n",
        "2. Logistic,\n",
        "3. ReLU,\n",
        "\n",
        "What are the three accuracy values you found?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5qUB7ScfZ1mc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We want to compare the accuries\n",
            "Tangent Hyperbolic Accuracy: 0.92\n",
            "ReLu Accuracy: 0.9\n",
            "Logistic Accuracy: 0.925\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate a synthetic dataset for binary classification\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an instance of MLPClassifier with softmax output activation\n",
        "clf = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=2000,\n",
        "                    activation='tanh')\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"We want to compare the accuries\")\n",
        "print(\"Tangent Hyperbolic Accuracy:\", accuracy)\n",
        "\n",
        "# Create an instance of MLPClassifier with softmax output activation\n",
        "clf = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=2000,\n",
        "                    activation='relu')\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"ReLu Accuracy:\", accuracy)\n",
        "\n",
        "# Create an instance of MLPClassifier with softmax output activation\n",
        "clf = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=2000,\n",
        "                    activation='logistic')\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
